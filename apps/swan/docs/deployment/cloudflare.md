# Cloudflare Workers Deployment

Deploy your Swan services to Cloudflare Workers for ultra-fast edge computing with global distribution across 275+ cities worldwide.

## Overview

Cloudflare Workers provide:

- **Sub-5ms cold starts** across 175+ countries
- **No servers to manage** - fully serverless
- **Built-in DDoS protection** and security
- **Pay-per-request pricing** starting free
- **Edge-side caching** and optimization

## Prerequisites

```bash
# Install Wrangler CLI
npm install -g wrangler

# Authenticate with Cloudflare
wrangler login
```

## Generated Configuration

Swan automatically generates `wrangler.toml`:

```toml
name = "my-service"
main = "src/index.js"
compatibility_date = "2023-10-03"
compatibility_flags = ["nodejs_compat"]

[env.production]
name = "my-service-prod"
vars = { ENVIRONMENT = "production" }

[env.staging]
name = "my-service-staging"
vars = { ENVIRONMENT = "staging" }

[[env.production.kv_namespaces]]
binding = "CACHE"
id = "your-kv-namespace-id"

[env.production.d1_databases]
binding = "DB"
database_name = "my-service-db"
database_id = "your-database-id"
```

## Service Code Structure

### Entry Point

```javascript
// src/index.js (generated by Swan)
import { Router } from "itty-router";
import { createCors } from "itty-cors";
import { UserService } from "./services/user.js";
import { Logger } from "./utils/logger.js";

const router = Router();
const { preflight, corsify } = createCors();

// Handle CORS preflight
router.all("*", preflight);

// Health check
router.get("/health", () => new Response("OK", { status: 200 }));

// User routes
router.get("/api/v1/users", async (request, env, ctx) => {
  const logger = new Logger(env);
  const userService = new UserService(env.DB, logger);

  try {
    const url = new URL(request.url);
    const limit = parseInt(url.searchParams.get("limit")) || 10;
    const offset = parseInt(url.searchParams.get("offset")) || 0;

    const users = await userService.getUsers(limit, offset);

    return new Response(
      JSON.stringify({
        data: users,
        meta: { limit, offset },
      }),
      {
        headers: { "Content-Type": "application/json" },
      }
    );
  } catch (error) {
    logger.error("Failed to fetch users", { error: error.message });
    return new Response(JSON.stringify({ error: "Internal server error" }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
});

router.post("/api/v1/users", async (request, env, ctx) => {
  const logger = new Logger(env);
  const userService = new UserService(env.DB, logger);

  try {
    const userData = await request.json();
    const user = await userService.createUser(userData);

    return new Response(JSON.stringify(user), {
      status: 201,
      headers: { "Content-Type": "application/json" },
    });
  } catch (error) {
    logger.error("Failed to create user", { error: error.message });

    if (error.message.includes("already exists")) {
      return new Response(JSON.stringify({ error: "User already exists" }), {
        status: 409,
        headers: { "Content-Type": "application/json" },
      });
    }

    return new Response(JSON.stringify({ error: "Internal server error" }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
});

// 404 handler
router.all("*", () => new Response("Not Found", { status: 404 }));

export default {
  fetch: (request, env, ctx) => router.handle(request, env, ctx).then(corsify),
};
```

### Database Integration (D1)

```javascript
// src/services/user.js
export class UserService {
  constructor(database, logger) {
    this.db = database;
    this.logger = logger;
  }

  async getUsers(limit = 10, offset = 0) {
    const { results } = await this.db
      .prepare(
        "SELECT id, email, name, created_at FROM users ORDER BY created_at DESC LIMIT ? OFFSET ?"
      )
      .bind(limit, offset)
      .all();

    return results.map((user) => ({
      ...user,
      created_at: new Date(user.created_at).toISOString(),
    }));
  }

  async getUserById(userId) {
    const { results } = await this.db
      .prepare("SELECT id, email, name, created_at FROM users WHERE id = ?")
      .bind(userId)
      .all();

    return results[0] || null;
  }

  async createUser(userData) {
    const userId = crypto.randomUUID();
    const now = Date.now();

    // Hash password using Web Crypto API
    const passwordHash = await this.hashPassword(userData.password);

    await this.db
      .prepare(
        "INSERT INTO users (id, email, name, password_hash, created_at, updated_at) VALUES (?, ?, ?, ?, ?, ?)"
      )
      .bind(userId, userData.email, userData.name, passwordHash, now, now)
      .run();

    return {
      id: userId,
      email: userData.email,
      name: userData.name,
      created_at: new Date(now).toISOString(),
    };
  }

  async hashPassword(password) {
    const encoder = new TextEncoder();
    const data = encoder.encode(password);
    const hash = await crypto.subtle.digest("SHA-256", data);

    return Array.from(new Uint8Array(hash))
      .map((b) => b.toString(16).padStart(2, "0"))
      .join("");
  }
}
```

## Database Setup (D1)

```bash
# Create D1 database
wrangler d1 create my-service-db

# Run migrations
wrangler d1 execute my-service-db --file=./schema.sql

# Connect to local database for development
wrangler d1 execute my-service-db --local --file=./schema.sql
```

```sql
-- schema.sql
CREATE TABLE users (
  id TEXT PRIMARY KEY,
  email TEXT UNIQUE NOT NULL,
  name TEXT,
  password_hash TEXT NOT NULL,
  created_at INTEGER NOT NULL,
  updated_at INTEGER NOT NULL
);

CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_created_at ON users(created_at DESC);
```

## Environment Variables & Secrets

```bash
# Set environment variables
wrangler secret put DATABASE_URL --env production
wrangler secret put JWT_SECRET --env production

# Set KV namespace for caching
wrangler kv:namespace create "CACHE" --env production
```

## Local Development

```bash
# Start local development server
wrangler dev --local --persist

# Test with local D1 database
wrangler dev --local --persist --d1 my-service-db
```

## Deployment Commands

```bash
# Deploy to staging
wrangler deploy --env staging

# Deploy to production
wrangler deploy --env production

# Deploy with custom name
wrangler deploy --name my-service-v2
```

## Monitoring & Analytics

### Built-in Analytics

Access analytics through Cloudflare dashboard:

- Request volume and latency
- Error rates by endpoint
- Geographic distribution
- Cache hit rates

### Custom Metrics

```javascript
// src/utils/metrics.js
export class Metrics {
  constructor(env) {
    this.env = env;
  }

  async recordRequest(path, method, status, duration) {
    // Send to Analytics Engine (if enabled)
    if (this.env.ANALYTICS) {
      await this.env.ANALYTICS.writeDataPoint({
        doubles: [duration],
        blobs: [path, method, status.toString()],
      });
    }
  }

  async recordError(error, context = {}) {
    console.error("Service error:", error, context);

    // Optional: Send to external monitoring
    if (this.env.SENTRY_DSN) {
      // Integration with Sentry or similar
    }
  }
}
```

## Caching Strategy

### Edge Caching

```javascript
// Automatic edge caching for GET requests
router.get("/api/v1/users/:id", async (request, env, ctx) => {
  const cacheKey = new Request(request.url);
  const cache = caches.default;

  // Check cache first
  let response = await cache.match(cacheKey);
  if (response) {
    return response;
  }

  // Fetch from database
  const userService = new UserService(env.DB, new Logger(env));
  const user = await userService.getUserById(request.params.id);

  if (!user) {
    return new Response("Not Found", { status: 404 });
  }

  // Create cacheable response
  response = new Response(JSON.stringify(user), {
    headers: {
      "Content-Type": "application/json",
      "Cache-Control": "public, max-age=300", // 5 minutes
    },
  });

  // Store in cache
  ctx.waitUntil(cache.put(cacheKey, response.clone()));

  return response;
});
```

### KV Storage

```javascript
// Use KV for application-level caching
export class CacheService {
  constructor(kv) {
    this.kv = kv;
  }

  async get(key) {
    const value = await this.kv.get(key);
    return value ? JSON.parse(value) : null;
  }

  async set(key, value, ttl = 300) {
    await this.kv.put(key, JSON.stringify(value), {
      expirationTtl: ttl,
    });
  }

  async delete(key) {
    await this.kv.delete(key);
  }
}
```

## Performance Optimization

### Bundle Size

Workers have a 1MB limit after compression:

```javascript
// Use dynamic imports for large dependencies
router.post("/api/v1/process", async (request, env, ctx) => {
  // Only load heavy processing when needed
  const { heavyProcessor } = await import("./heavy-processor.js");
  return heavyProcessor(request, env);
});
```

### Memory Usage

128MB memory limit per request:

```javascript
// Stream large responses
router.get("/api/v1/export", async (request, env, ctx) => {
  const { readable, writable } = new TransformStream();

  // Process data in chunks
  ctx.waitUntil(processLargeDataset(writable, env));

  return new Response(readable, {
    headers: { "Content-Type": "application/json" },
  });
});
```

## Security Best Practices

### Authentication

```javascript
// JWT validation using Web Crypto API
async function validateJWT(token, secret) {
  try {
    const [header, payload, signature] = token.split(".");

    // Verify signature using HMAC
    const encoder = new TextEncoder();
    const key = await crypto.subtle.importKey(
      "raw",
      encoder.encode(secret),
      { name: "HMAC", hash: "SHA-256" },
      false,
      ["verify"]
    );

    const isValid = await crypto.subtle.verify(
      "HMAC",
      key,
      new Uint8Array([...atob(signature)].map((c) => c.charCodeAt(0))),
      encoder.encode(`${header}.${payload}`)
    );

    if (!isValid) throw new Error("Invalid signature");

    return JSON.parse(atob(payload));
  } catch (error) {
    throw new Error("Invalid token");
  }
}
```

### Rate Limiting

```javascript
// Simple rate limiting with KV
async function rateLimit(request, env, key, limit = 100, window = 60) {
  const current = (await env.CACHE.get(key)) || 0;

  if (current >= limit) {
    return new Response("Rate limit exceeded", {
      status: 429,
      headers: { "Retry-After": window.toString() },
    });
  }

  await env.CACHE.put(key, (parseInt(current) + 1).toString(), {
    expirationTtl: window,
  });

  return null; // Continue processing
}
```

## CI/CD Integration

```yaml
# .github/workflows/deploy-cloudflare.yml
name: Deploy to Cloudflare Workers

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: "18"
          cache: "npm"

      - name: Install dependencies
        run: npm ci

      - name: Run tests
        run: npm test

      - name: Deploy to Staging
        if: github.event_name == 'pull_request'
        run: npx wrangler deploy --env staging
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}

      - name: Deploy to Production
        if: github.ref == 'refs/heads/main'
        run: npx wrangler deploy --env production
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
```

## Cost Optimization

### Free Tier Limits

- 100,000 requests/day
- 1,000 requests/minute burst
- 10ms CPU time per request

### Paid Plans

- Workers Paid: $5/month for 10M requests
- Additional requests: $0.50 per million
- KV storage: $0.50 per million reads

### Optimization Tips

1. **Cache aggressively** at edge and in KV
2. **Minimize CPU time** with efficient algorithms
3. **Use D1** for free database storage
4. **Compress responses** to reduce bandwidth
5. **Monitor usage** through Cloudflare dashboard
